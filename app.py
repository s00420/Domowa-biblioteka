import streamlit as st
import openai
import base64
import requests
import json
import os
import pandas as pd
import time
from authlib.integrations.requests_client import OAuth2Session
from urllib.parse import urlencode
from langfuse import Langfuse
from summary_evaluation import SummaryEvaluator
import tempfile
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
import io

def normalize_text(text):
    """
    Normalizuje tekst do por√≥wna≈Ñ - usuwa znaki specjalne, sprowadza do ma≈Çych liter,
    usuwa polskie znaki diakrytyczne.
    """
    if not text:
        return ""
    
    # Zamie≈Ñ polskie znaki na ich odpowiedniki bez diakrytyk√≥w
    polish_chars = {
        'ƒÖ': 'a', 'ƒá': 'c', 'ƒô': 'e', '≈Ç': 'l', '≈Ñ': 'n',
        '√≥': 'o', '≈õ': 's', '≈∫': 'z', '≈º': 'z',
        'ƒÑ': 'A', 'ƒÜ': 'C', 'ƒò': 'E', '≈Å': 'L', '≈É': 'N',
        '√ì': 'O', '≈ö': 'S', '≈π': 'Z', '≈ª': 'Z'
    }
    
    # Usu≈Ñ znaki specjalne i sprowad≈∫ do ma≈Çych liter
    text = text.lower()
    for char, replacement in polish_chars.items():
        text = text.replace(char, replacement)
    
    # Usu≈Ñ znaki specjalne i spacje
    text = ''.join(c for c in text if c.isalnum() or c.isspace())
    return text.strip()

def calculate_confidence(title, author, result):
    """
    Oblicza poziom pewno≈õci dopasowania wyniku wyszukiwania.
    """
    confidence = 0
    
    # Normalizuj teksty do por√≥wnania
    result_title = normalize_text(result.get("title", ""))
    search_title = normalize_text(title)
    
    # Por√≥wnanie tytu≈Ç√≥w
    if search_title == result_title:
        confidence += 0.6  # Dok≈Çadne dopasowanie
    elif search_title in result_title or result_title in search_title:
        confidence += 0.4  # Jeden zawiera siƒô w drugim
    else:
        # Sprawd≈∫ podobie≈Ñstwo s≈Ç√≥w
        search_words = set(search_title.split())
        result_words = set(result_title.split())
        common_words = search_words.intersection(result_words)
        if common_words:
            confidence += 0.2 * (len(common_words) / len(search_words))
    
    # Por√≥wnanie autor√≥w
    if author:
        result_authors = [normalize_text(a) for a in result.get("authors", [])]
        search_author = normalize_text(author)
        
        # Sprawd≈∫ dok≈Çadne dopasowanie autora
        if search_author in result_authors:
            confidence += 0.4
        else:
            # Sprawd≈∫ czƒô≈õciowe dopasowanie
            for result_author in result_authors:
                if search_author in result_author or result_author in search_author:
                    confidence += 0.3
                    break
                else:
                    # Sprawd≈∫ podobie≈Ñstwo s≈Ç√≥w w nazwisku
                    search_author_words = set(search_author.split())
                    result_author_words = set(result_author.split())
                    common_words = search_author_words.intersection(result_author_words)
                    if common_words:
                        confidence += 0.2 * (len(common_words) / len(search_author_words))
    
    return confidence

def search_book(title, author=None):
    """
    Wyszukuje ksiƒÖ≈ºkƒô w r√≥≈ºnych ≈∫r√≥d≈Çach.
    Zwraca najlepiej dopasowany wynik.
    """
    results = []
    
    # Przygotuj zapytanie
    if author:
        query = f"{title} {author}"
    else:
        query = title
    
    # Usu≈Ñ znaki specjalne i popraw formatowanie
    query = query.replace("(", "").replace(")", "").strip()
    
    # Wyszukiwanie w Google Books API
    try:
        url = f"https://www.googleapis.com/books/v1/volumes?q={requests.utils.quote(query)}&langRestrict=pl"
        result = requests.get(url)
        if result.status_code == 200:
            items = result.json().get("items", [])
            for item in items[:5]:  # Sprawd≈∫ 5 najlepszych wynik√≥w
                volume_info = item.get("volumeInfo", {})
                if volume_info:
                    results.append({
                        "source": "google",
                        "title": volume_info.get("title", ""),
                        "author": ", ".join(volume_info.get("authors", ["nieznany"])),
                        "year": volume_info.get("publishedDate", "brak danych"),
                        "confidence": calculate_confidence(title, author, volume_info)
                    })
    except Exception as e:
        st.error(f"B≈ÇƒÖd podczas wyszukiwania w Google Books: {str(e)}")
    
    # Wyszukiwanie w Open Library API
    try:
        url = f"https://openlibrary.org/search.json?q={requests.utils.quote(query)}&language=pol"
        result = requests.get(url)
        if result.status_code == 200:
            docs = result.json().get("docs", [])
            for doc in docs[:5]:  # Sprawd≈∫ 5 najlepszych wynik√≥w
                results.append({
                    "source": "openlibrary",
                    "title": doc.get("title", ""),
                    "author": ", ".join(doc.get("author_name", ["nieznany"])),
                    "year": doc.get("first_publish_year", "brak danych"),
                    "confidence": calculate_confidence(title, author, doc)
                })
    except Exception as e:
        st.error(f"B≈ÇƒÖd podczas wyszukiwania w Open Library: {str(e)}")
    
    # Wyszukiwanie w WorldCat API (je≈õli dostƒôpny)
    try:
        url = f"http://www.worldcat.org/webservices/catalog/search/worldcat/opensearch?q={requests.utils.quote(query)}&wskey=YOUR_WORLDCAT_KEY"
        result = requests.get(url)
        if result.status_code == 200:
            # Przetwarzanie wynik√≥w WorldCat
            # (tutaj dodaj kod do przetwarzania XML z WorldCat)
            pass
    except Exception as e:
        st.error(f"B≈ÇƒÖd podczas wyszukiwania w WorldCat: {str(e)}")
    
    # Wybierz najlepszy wynik
    if results:
        best_result = max(results, key=lambda x: x["confidence"])
        if best_result["confidence"] >= 0.3:  # Minimalny pr√≥g pewno≈õci
            return {
                "title": best_result["title"],
                "author": best_result["author"],
                "year": best_result["year"],
                "label": f"{best_result['title']} - {best_result['author']} ({best_result['year']})",
                "confidence": best_result["confidence"]
            }
    
    # Je≈õli nie znaleziono dobrego dopasowania, u≈ºyj oryginalnego rozpoznania
    return {
        "title": title,
        "author": author if author else "nieznany",
        "year": "brak danych",
        "label": f"{title} - {author if author else 'nieznany'} (brak danych)",
        "confidence": 0
    }

# Dodaj na poczƒÖtku pliku, po importach
class AppState:
    def __init__(self):
        self.current_summary = None
        self.predicted_rating = None
        self.summary_features = None
        self.rating_submitted = False
        self.last_summary_text = None
        self.last_prediction_time = None
        self.cache = {}

    def clear_state(self):
        self.current_summary = None
        self.predicted_rating = None
        self.summary_features = None
        self.rating_submitted = False
        self.last_summary_text = None
        self.last_prediction_time = None

# Inicjalizacja stanu aplikacji
if 'app_state' not in st.session_state:
    st.session_state.app_state = AppState()

# Inicjalizacja Langfuse z Streamlit secrets
try:
    lf = Langfuse(
        public_key=os.environ["langfuse_public_key"],
        secret_key=os.environ["langfuse_secret_key"],
        host=os.environ["langfuse_host"]
    )
    st.session_state["langfuse_initialized"] = True
except Exception as e:
    st.error(f"B≈ÇƒÖd inicjalizacji Langfuse: {str(e)}")
    st.session_state["langfuse_initialized"] = False

# --- Konfiguracja klienta OpenAI ---
client = openai.OpenAI(api_key=os.environ["openai_api_key"])

st.set_page_config(page_title="Domowa Biblioteka", layout="wide")

# --- Logowanie przez Google OAuth ---
GOOGLE_CLIENT_ID = os.environ["google_client_id"]
GOOGLE_CLIENT_SECRET = os.environ["google_client_secret"]
REDIRECT_URI = os.environ["redirect_uri"]

def get_google_auth_url():
    params = {
        "client_id": GOOGLE_CLIENT_ID,
        "redirect_uri": REDIRECT_URI,
        "response_type": "code",
        "scope": "openid email profile",
        "access_type": "offline",
        "prompt": "consent",
    }
    base_url = "https://accounts.google.com/o/oauth2/v2/auth"
    auth_url = f"{base_url}?{urlencode(params)}"
    return auth_url

def get_google_user_info(code):
    token_url = "https://oauth2.googleapis.com/token"
    userinfo_url = "https://openidconnect.googleapis.com/v1/userinfo"

    data = {
        "code": code,
        "client_id": GOOGLE_CLIENT_ID,
        "client_secret": GOOGLE_CLIENT_SECRET,
        "redirect_uri": REDIRECT_URI,
        "grant_type": "authorization_code"
    }

    headers = {
        "Content-Type": "application/x-www-form-urlencoded"
    }

    token_response = requests.post(token_url, data=urlencode(data), headers=headers)

    if token_response.status_code != 200:
        st.error(f"B≈ÇƒÖd pobierania tokenu: {token_response.text}")
        st.stop()

    tokens = token_response.json()

    headers = {"Authorization": f"Bearer {tokens['access_token']}"}
    userinfo_response = requests.get(userinfo_url, headers=headers)
    userinfo_response.raise_for_status()

    return userinfo_response.json()

# --- Dodanie przycisku wylogowania ---
if st.sidebar.button("Wyloguj"):
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    st.query_params.clear()
    st.rerun()

if "user_email" not in st.session_state:
    params = st.query_params
    if "code" in params:
        code = params["code"] if isinstance(params["code"], str) else params["code"][0]
        user_info = get_google_user_info(code)
        st.session_state.user_email = user_info.get("email")
        st.rerun()
    else:
        auth_url = get_google_auth_url()
        if st.button("üîí Zaloguj siƒô przez Google"):
            st.query_params.clear()
            st.markdown(f"<meta http-equiv='refresh' content='0; url={auth_url}'>", unsafe_allow_html=True)
            st.stop()
        st.stop()

user_email = st.session_state.user_email
st.sidebar.success(f"Zalogowano jako: {user_email}")

# --- Funkcje pomocnicze ---
def load_rating_history():
    try:
        # Upewnij siƒô, ≈ºe ewaluator jest zainicjalizowany
        evaluator._initialize()
        
        # Pobierz listƒô plik√≥w z ocenami
        ratings_response = evaluator._s3.list_objects_v2(
            Bucket=evaluator._bucket_name,
            Prefix='ratings/'
        )
        if 'Contents' not in ratings_response:
            return pd.DataFrame()
            
        ratings_files = [obj['Key'] for obj in ratings_response['Contents'] 
                        if obj['Key'].endswith('.json')]
        
        all_ratings = []
        for file in ratings_files:
            # Pobierz plik z S3
            data = evaluator._s3.get_object(Bucket=evaluator._bucket_name, Key=file)
            content = data['Body'].read().decode('utf-8')
            rating_data = json.loads(content)
            all_ratings.append(rating_data)
        
        if not all_ratings:
            return pd.DataFrame()
            
        return pd.DataFrame(all_ratings)
    except Exception as e:
        print(f"B≈ÇƒÖd podczas wczytywania historii ocen: {str(e)}")
        return pd.DataFrame()

# --- G≈Ç√≥wna aplikacja po zalogowaniu ---
st.title("üìö Domowa Biblioteka")

st.header("Moja p√≥≈Çka")

# Inicjalizacja ewaluatora
evaluator = SummaryEvaluator()

# Funkcje pomocnicze
@st.cache_data
def load_user_books(user_email):
    user_file = f"user_shelves/{user_email.replace('@', '_at_')}.json"
    if os.path.exists(user_file):
        with open(user_file, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_user_books(user_email, books):
    os.makedirs("user_shelves", exist_ok=True)
    user_file = f"user_shelves/{user_email.replace('@', '_at_')}.json"
    try:
        if os.path.exists(user_file):
            with open(user_file, "r", encoding="utf-8") as f:
                existing_books = json.load(f)
        else:
            existing_books = []
        
        # Sprawd≈∫, kt√≥re ksiƒÖ≈ºki sƒÖ nowe (tylko tytu≈Ç i autor)
        existing_books_set = {(b["title"].lower(), b["author"].lower()) for b in existing_books}
        new_books = []
        for b in books:
            book_key = (b["title"].lower(), b["author"].lower())
            if book_key not in existing_books_set:
                new_books.append({
                    "title": b["title"],
                    "author": b["author"]
                })
        
        if new_books:
            # Dodaj nowe ksiƒÖ≈ºki do istniejƒÖcych
            updated_books = existing_books + new_books
            with open(user_file, "w", encoding="utf-8") as f:
                json.dump(updated_books, f, ensure_ascii=False, indent=2)
            st.success(f"Dodano {len(new_books)} nowych ksiƒÖ≈ºek.")
            time.sleep(2)
            # Od≈õwie≈º dane u≈ºytkownika
            st.session_state["user_books"] = updated_books
            st.rerun()
        else:
            st.info("Wszystkie wybrane ksiƒÖ≈ºki ju≈º znajdujƒÖ siƒô na Twojej p√≥≈Çce.")
            time.sleep(2)
    except Exception as e:
        st.error(f"B≈ÇƒÖd podczas zapisywania ksiƒÖ≈ºek: {str(e)}")

def delete_book_from_shelf(user_email, title, author):
    user_file = f"user_shelves/{user_email.replace('@', '_at_')}.json"
    if os.path.exists(user_file):
        with open(user_file, "r", encoding="utf-8") as f:
            books = json.load(f)
        updated_books = [b for b in books if not (b["title"].lower() == title.lower() and b["author"].lower() == author.lower())]
        with open(user_file, "w", encoding="utf-8") as f:
            json.dump(updated_books, f, ensure_ascii=False, indent=2)

# Za≈Çaduj ksiƒÖ≈ºki u≈ºytkownika
if "user_books" not in st.session_state:
    st.session_state["user_books"] = load_user_books(user_email)

user_books = st.session_state["user_books"]

available_authors = sorted(set(b["author"] for b in user_books))
available_titles = sorted(set(b["title"] for b in user_books))

st.sidebar.markdown("### Filtry")
author_filter = st.sidebar.selectbox("Filtruj wg autora", [""] + available_authors)
title_filter = st.sidebar.selectbox("Filtruj wg tytu≈Çu", [""] + available_titles)

filtered_books = user_books
if author_filter:
    filtered_books = [b for b in filtered_books if author_filter.lower() in b["author"].lower()]
if title_filter:
    filtered_books = [b for b in filtered_books if title_filter.lower() in b["title"].lower()]

if filtered_books:
    df_books = pd.DataFrame(filtered_books)
    # Usu≈Ñ kolumny year i label
    df_books = df_books[["title", "author"]]
    # Zmie≈Ñ nazwy kolumn na polskie
    df_books.columns = ["Tytu≈Ç", "Autor"]
    # Posortuj po tytule
    df_books = df_books.sort_values("Tytu≈Ç")
    # Zresetuj indeks, zaczynajƒÖc od 1
    df_books.index = range(1, len(df_books) + 1)
    
    # Wy≈õwietl tabelƒô
    st.dataframe(df_books, use_container_width=True)
    
    # Lista ksiƒÖ≈ºek do wyboru
    book_list = ["(brak)"] + [f"{b['title']} - {b['author']}" for b in filtered_books]
    
    # Inicjalizacja stanu dla wyboru ksiƒÖ≈ºki
    if "book_selectbox" not in st.session_state:
        st.session_state.book_selectbox = "(brak)"
    if "selected_book" not in st.session_state:
        st.session_state.selected_book = "(brak)"
    
    # Funkcja do aktualizacji wybranej ksiƒÖ≈ºki
    def update_selected_book():
        if "book_selectbox" in st.session_state:
            st.session_state.selected_book = st.session_state.book_selectbox
    
    # Selectbox z callbackiem
    selected_book = st.selectbox(
        "Wybierz ksiƒÖ≈ºkƒô z p√≥≈Çki",
        book_list,
        key="book_selectbox",
        on_change=update_selected_book
    )

    col1, col2 = st.columns(2)

    if st.session_state.selected_book != "(brak)":
        if col1.button("üìÑ Wygeneruj streszczenie"):
            # Rozdziel tytu≈Ç i autora
            parts = st.session_state.selected_book.split(" - ")
            title_for_summary = parts[0].strip()
            author_for_summary = parts[1].strip()

            # Wy≈õwietl placeholder podczas generowania
            with st.spinner('Generowanie streszczenia...'):
                response = client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": (
                            "Twoim zadaniem jest przygotowanie kr√≥tkiego streszczenia ksiƒÖ≈ºki w maksymalnie 5 zdaniach."
                            "Szukaj w sieci dostƒôpnych informacji, ale je≈õli nie znajdziesz wystarczajƒÖcych informacji, napisz: "
                            "'Nie mam wystarczajƒÖcej wiedzy o tej ksiƒÖ≈ºce, aby przygotowaƒá streszczenie.'"
                        )},
                        {"role": "user", "content": (
                            f"Stw√≥rz streszczenie ksiƒÖ≈ºki pod tytu≈Çem '{title_for_summary}', napisanej przez '{author_for_summary}'."
                        )}
                    ],
                    max_tokens=300
                )
                summary = response.choices[0].message.content
                st.session_state.app_state.current_summary = summary
                st.session_state.app_state.predicted_rating = None
                st.rerun()

        # Wy≈õwietl streszczenie i przewidywanie oceny
        if st.session_state.app_state.current_summary:
            st.subheader("Wygenerowane streszczenie")
            st.write(st.session_state.app_state.current_summary)
            
            # Przewidywanie oceny tylko raz, przy pierwszym wy≈õwietleniu streszczenia
            if st.session_state.app_state.predicted_rating is None and not st.session_state.app_state.rating_submitted:
                with st.spinner("Przewidywanie oceny..."):
                    predicted_rating = evaluator.predict_rating(st.session_state.app_state.current_summary)
                    st.session_state.app_state.predicted_rating = predicted_rating
                    st.session_state.app_state.last_prediction_time = datetime.now().isoformat()
            
            # Wy≈õwietl przewidywanie oceny je≈õli jest dostƒôpne
            if st.session_state.app_state.predicted_rating is not None:
                st.info(f"Przewidywana ocena: {st.session_state.app_state.predicted_rating:.1f}/5.0")
            else:
                st.info("Nie mo≈ºna przewidzieƒá oceny - brak wystarczajƒÖcej liczby danych treningowych")
            
            # Wyb√≥r oceny przez u≈ºytkownika
            st.subheader("Oce≈Ñ streszczenie")
            # U≈ºyj session_state do przechowywania oceny u≈ºytkownika
            if 'user_rating' not in st.session_state:
                st.session_state.user_rating = 3.0
            
            # Suwak do zmiany oceny - zmiana nie wywo≈Çuje ≈ºadnych akcji
            user_rating = st.slider(
                "Twoja ocena (1-5)", 
                1.0, 5.0, 
                st.session_state.user_rating, 
                0.5,
                key="rating_slider",
                on_change=None  # Wy≈ÇƒÖczamy reakcjƒô na zmianƒô
            )
            
            # Aktualizuj warto≈õƒá w session_state tylko gdy u≈ºytkownik kliknie przycisk zapisu
            if st.button("Zapisz streszczenie"):
                st.session_state.user_rating = user_rating
                st.session_state.app_state.rating_submitted = True
                with st.spinner("Zapisywanie streszczenia i oceny..."):
                    try:
                        # Pobierz tytu≈Ç i autora z wybranej ksiƒÖ≈ºki
                        selected_book_parts = st.session_state.selected_book.split(" - ")
                        book_title = selected_book_parts[0].strip()
                        book_author = selected_book_parts[1].strip()
                        
                        # Generuj unikalny ID dla streszczenia
                        summary_id = f"summary_{int(time.time())}_{hash(st.session_state.app_state.current_summary) % 10000}"
                        
                        # Zapisz streszczenie i ocenƒô
                        evaluator.save_summary_and_rating(
                            summary_id=summary_id,
                            summary_text=st.session_state.app_state.current_summary,
                            rating=user_rating,
                            book_title=book_title,
                            book_author=book_author
                        )
                        
                        st.success("Streszczenie i ocena zosta≈Çy zapisane!")
                        
                        # Wyczy≈õƒá stan po zapisaniu
                        st.session_state.app_state.current_summary = None
                        st.session_state.app_state.predicted_rating = None
                        st.session_state.user_rating = 3.0  # Reset oceny u≈ºytkownika
                        
                        # Od≈õwie≈º statystyki tylko po zapisaniu nowego streszczenia
                        st.session_state["stats_updated"] = False
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"B≈ÇƒÖd podczas zapisywania: {str(e)}")

        if col2.button("üóëÔ∏è Usu≈Ñ ksiƒÖ≈ºkƒô"):
            parts = st.session_state.selected_book.split(" - ")
            title_to_delete = parts[0].strip()
            author_to_delete = parts[1].strip()
            delete_book_from_shelf(user_email, title_to_delete, author_to_delete)
            st.success("KsiƒÖ≈ºka zosta≈Ça usuniƒôta z p√≥≈Çki.")
            time.sleep(2)
            st.rerun()
else:
    st.info("Brak ksiƒÖ≈ºek spe≈ÇniajƒÖcych kryteria.")

# --- Upload i rozpoznawanie ksiƒÖ≈ºek ze zdjƒôcia ---
st.sidebar.markdown("---")
st.sidebar.markdown("### Rozpoznaj ksiƒÖ≈ºki ze zdjƒôcia")

uploaded_file = st.sidebar.file_uploader("Za≈Çaduj zdjƒôcie swojej p√≥≈Çki", type=["jpg", "jpeg", "png"])
if uploaded_file:
    st.sidebar.image(uploaded_file, caption="Za≈Çadowane zdjƒôcie", use_container_width=True)
    file_bytes = uploaded_file.read()

    if st.sidebar.button("üîç Rozpoznaj ksiƒÖ≈ºki"):
        base64_image = base64.b64encode(file_bytes).decode("utf-8")

        # --- START Langfuse ≈õledzenie ---
        if st.session_state.get("langfuse_initialized", False):
            try:
                trace = lf.trace(
                    name="book_recognition",
                    user_id=user_email,
                    metadata={"total_books": len(user_books)},
                    model="gpt-4-turbo"
                )
                generation = trace.generation(
                    name="image_to_books",
                    input={"image_base64_length": len(base64_image) if "base64_image" in locals() else 0},
                    model="gpt-4-turbo"
                )
            except Exception as e:
                st.error(f"B≈ÇƒÖd podczas inicjalizacji ≈õledzenia Langfuse: {str(e)}")
        # --- END START ---

        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": (
                                """Na podstawie za≈ÇƒÖczonym zdjƒôciu rozpoznaj wszystkie mo≈ºliwe teksty. 
                                W≈õr√≥d tych tekst√≥w rozpoznaj tytu≈Çy ksiƒÖ≈ºek oraz ich autor√≥w.
                                Za≈Ç√≥≈º ≈ºe wiƒôkszo≈õƒá tekst√≥w jest w jƒôzyku polskim, ale mogƒÖ siƒô trafiƒá r√≥wnie≈º w innym jƒôzyku. 
                                KsiƒÖ≈ºek mo≈ºe byƒá wiƒôcej ni≈º jedna, a grzbiety mogƒÖ byƒá w uk≈Çadzie zar√≥wno pionowym jak i poziomym"""
                                "Wypisz listƒô w formacie: Tytu≈Ç - Autor. Je≈õli autor jest nieczytelny, zostaw puste. Nie dodawaj ≈ºadnych innych komentarzy"
                                "Ka≈ºdƒÖ pozycjƒô wypisz w nowej linii."
                            )
                        },
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
                        }
                    ]
                }
            ],
            max_tokens=4000
        )
        lines_raw = response.choices[0].message.content
        lines = [line.strip() for line in lines_raw.split("\n") if line.strip()]
        enriched = []
        for line in lines:
            if "-" in line:
                title, author = map(str.strip, line.split("-", 1))
            else:
                title = line.strip()
                author = None
            
            # Wyszukaj ksiƒÖ≈ºkƒô
            book_info = search_book(title, author)
            if book_info:
                enriched.append(book_info)
            else:
                # Je≈õli nie znaleziono dopasowania, u≈ºyj oryginalnego rozpoznania
                enriched.append({
                    "title": title,
                    "author": author if author else "nieznany",
                    "year": "brak danych",
                    "label": f"{title} - {author if author else 'nieznany'} (brak danych)"
                })

        if enriched:
            st.session_state["recognized_books"] = enriched
            st.success(f"Rozpoznano {len(enriched)} ksiƒÖ≈ºek!")
        else:
            st.session_state["recognized_books"] = []
            st.warning("Nie rozpoznano ≈ºadnych ksiƒÖ≈ºek na zdjƒôciu.")

        # --- DOMKNIJ Langfuse generation ---
        if st.session_state.get("langfuse_initialized", False):
            try:
                # Pobierz informacje o tokenach z odpowiedzi OpenAI
                token_usage = {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens
                }
                
                generation.end(
                    output=response.choices[0].message.content,
                    usage=token_usage,
                    metadata={
                        "recognized_books_count": len(enriched),
                        "image_size": len(base64_image),
                        "model": response.model,
                        "token_usage": token_usage
                    }
                )
                trace.update(
                    status="COMPLETED",
                    metadata={
                        "total_books_recognized": len(enriched),
                        "token_usage": token_usage
                    }
                )
            except Exception as e:
                st.error(f"B≈ÇƒÖd podczas zamykania ≈õledzenia Langfuse: {str(e)}")

recognized_books = st.session_state.get("recognized_books", [])
if recognized_books:
    st.sidebar.markdown("### Rozpoznane ksiƒÖ≈ºki")
    selected_books = st.sidebar.multiselect(
        "Wybierz ksiƒÖ≈ºki do dodania:",
        [f"{book['title']} - {book['author']}" for book in recognized_books],
        default=[], 
        key="book_select"
    )
    if st.sidebar.button("‚úÖ Dodaj wybrane ksiƒÖ≈ºki"):
        existing = load_user_books(user_email)
        existing_books_set = {(b["title"].lower(), b["author"].lower()) for b in existing}
        new_books = []
        
        for book_str in selected_books:
            parts = book_str.split(" - ")
            title = parts[0].strip()
            author = parts[1].strip()
            if (title.lower(), author.lower()) not in existing_books_set:
                new_books.append({
                    "title": title,
                    "author": author
                })
        
        if new_books:
            save_user_books(user_email, new_books)
            # Wyczy≈õƒá stan rozpoznanych ksiƒÖ≈ºek przed od≈õwie≈ºeniem
            if "recognized_books" in st.session_state:
                del st.session_state["recognized_books"]
            st.rerun()  # Od≈õwie≈º stronƒô po dodaniu ksiƒÖ≈ºek
        else:
            st.info("Wszystkie wybrane ksiƒÖ≈ºki ju≈º znajdujƒÖ siƒô na Twojej p√≥≈Çce.")
            time.sleep(2)
            # Wyczy≈õƒá stan rozpoznanych ksiƒÖ≈ºek
            if "recognized_books" in st.session_state:
                del st.session_state["recognized_books"]
            st.rerun()

# --- Dodawanie ksiƒÖ≈ºki rƒôcznie ---
st.sidebar.markdown("---")
st.sidebar.markdown("### Dodaj ksiƒÖ≈ºkƒô rƒôcznie")

manual_form = st.sidebar.form(key="manual_form")
with manual_form:
    title = st.text_input("Tytu≈Ç")
    author = st.text_input("Autor")
    submitted = st.form_submit_button("‚ûï Dodaj ksiƒÖ≈ºkƒô")
    if submitted:
        if title and author:
            # Sprawd≈∫, czy ksiƒÖ≈ºka ju≈º istnieje
            existing = load_user_books(user_email)
            if any(b["title"].lower() == title.lower() and b["author"].lower() == author.lower() for b in existing):
                st.warning("Ta ksiƒÖ≈ºka ju≈º znajduje siƒô na Twojej p√≥≈Çce.")
                time.sleep(2)
            else:
                new_book = {
                    "title": title,
                    "author": author
                }
                save_user_books(user_email, [new_book])
                st.success("KsiƒÖ≈ºka zosta≈Ça dodana do Twojej p√≥≈Çki.")
                time.sleep(2)
                st.rerun()
        else:
            st.warning("Tytu≈Ç i autor muszƒÖ byƒá uzupe≈Çnione.")
            time.sleep(2)

# --- Statystyki i historia streszcze≈Ñ ---
st.markdown("---")
st.markdown("### üìä Statystyki i historia streszcze≈Ñ")

# Wy≈õwietl statystyki tylko je≈õli zosta≈Çy zaktualizowane
if not st.session_state.get("stats_updated", False):
    ratings_df = load_rating_history()
    if not ratings_df.empty:
        # Statystyki og√≥lne
        avg_rating = ratings_df['rating'].mean()
        total_ratings = len(ratings_df)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("≈örednia ocena", f"{avg_rating:.2f}")
        with col2:
            st.metric("Liczba ocen", total_ratings)
        
        # Wykres rozk≈Çadu ocen
        fig = px.histogram(ratings_df, x='rating', 
                          title='Rozk≈Çad ocen',
                          labels={'rating': 'Ocena', 'count': 'Liczba ocen'},
                          nbins=5)
        fig.update_layout(bargap=0.2)
        st.plotly_chart(fig, use_container_width=True)
        
        # Trend ocen w czasie
        ratings_df['timestamp'] = pd.to_datetime(ratings_df['timestamp'])
        ratings_df = ratings_df.sort_values('timestamp')
        ratings_df['cumulative_avg'] = ratings_df['rating'].expanding().mean()
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=ratings_df['timestamp'], 
                                y=ratings_df['cumulative_avg'],
                                mode='lines+markers',
                                name='≈örednia ocena'))
        fig.update_layout(title='Trend ocen w czasie',
                         xaxis_title='Data',
                         yaxis_title='≈örednia ocena')
        st.plotly_chart(fig, use_container_width=True)
        
        # Oznacz statystyki jako zaktualizowane
        st.session_state["stats_updated"] = True
    else:
        st.info("Brak danych do wy≈õwietlenia statystyk")
            